max_num_tokens: 8192
max_batch_size: 32
max_seq_len: 81920
enable_chunked_prefill: true
tensor_parallel_size: 4
moe_expert_parallel_size: 2
kv_cache_config:
  dtype: fp8
  free_gpu_memory_fraction: 0.90
  enable_block_reuse: true
cuda_graph_config:
  enable_padding: false
  max_batch_size: 64
print_iter_log: true
moe_config:
  backend: TRTLLM
torch_compile_config:
  capture_num_tokens: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 768, 1024, 1280, 1536, 1792, 2048, 2304, 2560, 2816, 3072, 3328, 3584]
  enable_userbuffers: false
  max_num_streams: 2
  enable_piecewise_cuda_graph: true
